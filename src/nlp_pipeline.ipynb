{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd448df",
   "metadata": {},
   "source": [
    "# Collection Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b01e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def all_files_in_folder(current_folder_path):\n",
    "    \"\"\"Gets all names of the files in the 'current' folder.\"\"\"\n",
    "    files_list = []\n",
    "    files_n_dirs = os.listdir(current_folder_path) # folders and files in current folder\n",
    "\n",
    "    for i,file in enumerate(files_n_dirs):\n",
    "        if i == 4:\n",
    "            break\n",
    "        else:\n",
    "            path_to_file = os.path.join(current_folder_path,file) # folder abs path + file_name\n",
    "            is_file = os.path.isfile(path_to_file)\n",
    "            if is_file == True:\n",
    "                files_list.append(path_to_file)\n",
    "    return files_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5d2ab",
   "metadata": {},
   "source": [
    "# Analysis Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d76b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_oov_tokens(cleaned_reviews):\n",
    "    \"\"\"Returns a set of out-of-vocabulary tokens.\n",
    "       Use it to check which words in our review content\n",
    "       are unrecognisable to SpaCy.\n",
    "    \"\"\"\n",
    "    oov_tokens = set()\n",
    "    \n",
    "    for review in cleaned_reviews:\n",
    "        cleaned_reviews_doc = loaded_lang_model(review)\n",
    "\n",
    "        for token in cleaned_reviews_doc:\n",
    "            if token.is_oov and (not token.is_space):\n",
    "                oov_tokens.add(token.text)\n",
    "    return oov_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3520e0b8",
   "metadata": {},
   "source": [
    "# Cleaning Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93233a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Removes punctuation.\"\"\"\n",
    "    acceptable = ['Â£','%']\n",
    "    text = text.replace('\\n', \" \").replace('\\t','').replace('\\r','')\n",
    "    clean_chars = [char.lower() for char in text if char.isalnum() or char.isspace() or (char in acceptable)]\n",
    "    return \"\".join(clean_chars)\n",
    "\n",
    "def lemmatise_and_rmv_stopwords(review):\n",
    "    \"\"\"Returns lemmatised review content without stopwords.\"\"\"\n",
    "    parser = English()\n",
    "    review = parser(review)\n",
    "    clean = \" \".join([token.lemma_ for token in review if ((token.is_stop == False) and (token.is_space == False))])\n",
    "    return clean\n",
    "\n",
    "def prepare_txt_for_lda(text):\n",
    "    \"\"\"Filters out words shorter than 5 characters. Returns filtered tokens.\"\"\"\n",
    "    tokens = [token for token in text if len(token) > 4]\n",
    "    return tokens    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1e792",
   "metadata": {},
   "source": [
    "### Step 4.3 onwards functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45b63a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_freq(reviews_list):\n",
    "    \"\"\"Returns the frequencies of each token.\"\"\"\n",
    "    freq_dict = {}\n",
    "    for review in reviews_list:\n",
    "        for token in review:\n",
    "            if token not in freq_dict:\n",
    "                freq_dict[token] = 1\n",
    "            else:\n",
    "                freq_dict[token] += 1\n",
    "    return freq_dict\n",
    "\n",
    "\n",
    "def remove_one_freq_words(freq_dict, reviews_list):\n",
    "    \"\"\"Returns a list of reviews with words that appear only once removed.\"\"\"\n",
    "    clean_reviews = [  # double list comprehension :O\n",
    "                [token for token in review if freq_dict[token] > 1]\n",
    "                for review in reviews_list\n",
    "            ]\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a3bb7",
   "metadata": {},
   "source": [
    "# Main body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b6160",
   "metadata": {},
   "source": [
    "## Read in reviews into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35677fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from spacy.lang.en import English\n",
    "\n",
    "folder = '/home/mrfox/Desktop/bt_group_project/data'\n",
    "list_of_review_files = all_files_in_folder(folder) # return a list of all files in folder\n",
    "\n",
    "list_of_reviews = []\n",
    "for file in list_of_review_files: #iterate over files list, read each file, append review text to list_of_reviews\n",
    "    with open(file) as csv_f:\n",
    "        file_reader = csv.reader(csv_f)\n",
    "        \n",
    "        for row in file_reader:\n",
    "            content = row[0][:-3] # removes the tildes\n",
    "            list_of_reviews.append(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69324151",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Clean the reviews in the list for NLP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "643fbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews = []\n",
    "for review in list_of_reviews:\n",
    "    no_punct_review = remove_punctuation(review)\n",
    "    lemmatised_no_stop_review = lemmatise_and_rmv_stopwords(no_punct_review)\n",
    "    no_short_tokens_review = prepare_txt_for_lda(lemmatised_no_stop_review) # remove tokens that are too short\n",
    "    clean_reviews.append(no_short_tokens_review)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c87f9a",
   "metadata": {},
   "source": [
    "## Remove words that appear only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b988be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = calc_freq(clean_reviews)\n",
    "freq_adj_revs = remove_one_freq_words(freq_dict, clean_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b560c2",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f740338",
   "metadata": {},
   "source": [
    "## Creating a gensim dictionary and Transforming the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc4bd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "revs_dict = corpora.Dictionary(freq_adj_revs)\n",
    "rev_corpus = [revs_dict.doc2bow(review) for review in freq_adj_revs] # trains the corpus using BAG OF WORDS Model\n",
    "# this means that our corpus is represented in terms of numbers\n",
    "tf_idf = models.TfidfModel(rev_corpus) # calc doc freqs of all features of the corpus\n",
    "# apply doc2bow --> tf-idf to the whole corpus:\n",
    "rev_corpus_transformed = tf_idf[rev_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b297987",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2c7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2567433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59cf80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23408006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00844b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc115b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69443be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
